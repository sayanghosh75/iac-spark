---
# Copyright 2019, 2020. IBM All Rights Reserved.
# #
# # Licensed under the Apache License, Version 2.0 (the "License");
# # you may not use this file except in compliance with the License.
# # You may obtain a copy of the License at
# #
# # https://www.apache.org/licenses/LICENSE-2.0
# #
# # Unless required by applicable law or agreed to in writing, software
# # distributed under the License is distributed on an "AS IS" BASIS,
# # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# # See the License for the specific language governing permissions and
# # limitations under the License.
# #

- name: Install Spark, Scala and PySpark 
  hosts: sparklers, !localhost
#  hosts: localhost
  
  vars:
    distro_path: /home/Distros

    packages:
      - default-jdk
      - python3
      - python3-pip
      - python3-setuptools
      - python3-dev
      - python3-wheel
      - python3-matplotlib
      - firewalld


    pypackages:
      - selinux:
          name: selinux
          version:
      - pyspark:
          name: pyspark
          version: 3.0.0
      - numpy:
          name: numpy
          version:
      - pandas:
          name: pandas
          version:
      - tensorflow:
          name: tensorflow
          version: 2.2.0
      - h5py:
          name: h5py
          version:
      - keras:
          name: keras
          version:
      - tensorboard:
          name: tensorboard
          version:
      - systemml:
          name: systemml
          version:
      - jupyter:
          name: jupyter
          version:

    
    distros:
      scala:
        file: scala-2.13.2.tgz
        url:  https://downloads.lightbend.com/scala/2.13.2/scala-2.13.2.tgz
        extract_path: /home/Distros/scala
        install_path: /usr/local/scala
      spark:
        file: spark-2.4.6-bin-hadoop2.7.tgz
        url: https://apachemirror.sg.wuchna.com/spark/spark-2.4.6/spark-2.4.6-bin-hadoop2.7.tgz 
        extract_path: /home/Distros/spark
        install_path: /usr/local/spark

      
  tasks:

    - name: Confirm necessary packages are installed
      yum:
        name: "{{ packages }}"
        state: latest
      ignore_errors: true

    - name: Confirm default configurations on target
      include_tasks: infra-setup.yml

    - name: Create the Distro's directory
      file:
        path: "{{ distro_path }}"
        state: directory
        mode: 0755

    - name: Create directories, fetch tar and extract
      include_tasks:  spark-extract.yml
      with_dict: "{{ distros }}"

    - name: Install the extracted files to the correct location
      include_tasks:  spark-install.yml
      with_dict:  "{{ distros }}"

    - name: Update user path
      become: false
      lineinfile:
        line: "export PATH=$PATH:/usr/local/spark/bin:/usr/local/scala/bin"
        path: ~/.bashrc
        state: present
        #state: absent

    - name: Update python3 as version to use with spark
      become: false
      lineinfile:
        line: "export PYSPARK_PYTHON=python3"
        path: ~/.bashrc
        state: present
        #state: absent

    - name: Install Python modules
      include_tasks: python-install.yml
      with_dict: "{{ pypackages }}"

    - name: configure jupyter notebook
      include_tasks: jupyter-setup.yml
...       

